# Book Recommendation System

## Abstract
This study explores the complex link between an author's prolificacy—measured by the quantity of books they have written—and the average reviews their works earn. By means of an extensive examination that encompasses a wide range of writers and their literary works, this research reveals complex dynamics that exist within the literary domain. As expected, the results show that there isn't a clear-cut relationship between prolificacy and perceived quality as measured by average ratings. Some prolific writers have a large body of work and are continuously rated highly, whereas others show different patterns or stability despite their prolific production. This finding highlights the possibility that the sheer number of literary works may not be the only factor influencing perceived quality, underscoring the vital significance of upholding uniform standards.

The study technique begins with a detailed analysis of the datasets, closely examining column names, data types, and first rows to understand the structure of the datasets. The next phases pertain to the handling of outliers and missing results, which are significant factors that may affect the analysis's accuracy. The features of each column are taken into consideration when deciding which missing data management techniques, such imputation or removal, to use. The study also looks at possible duplicate records, offering insights into the process of deciding whether to keep or delete duplicate instances.

Exploratory Data Analysis (EDA) is a critical process used in the study to comprehend and analyze the large-scale information that was collected via web scraping. EDA is essential for exposing the dataset's intrinsic patterns, structural subtleties, and integrity. Through the process of determining the connections between important characteristics like authors, years of publication, and user ratings, EDA helps to reveal the complex processes that influence our tastes in literature.

An essential part of this research is web scraping, which makes it possible to automatically retrieve data from different internet sources. HTML pages are parsed in order to retrieve relevant information, which is then stored for further study. Web scraping is important because it detects fake or biased review of books. This feature makes it possible for companies, scholars, and developers to compile important data that advances our knowledge of the complex relationship between authorship and literature.
